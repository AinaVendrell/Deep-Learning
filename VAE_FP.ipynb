{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Copia de 3000pupurri.ipynb","provenance":[{"file_id":"1TwyknJDm3xcDh2vMqE723C8pcq5d1w98","timestamp":1591889361211}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"-gvvbYBidSPX","colab_type":"code","outputId":"63610b9c-b1eb-4325-d5b9-56fe9320d32a","executionInfo":{"status":"ok","timestamp":1591870218860,"user_tz":-120,"elapsed":954,"user":{"displayName":"PAULA VILAMITJANA I","photoUrl":"","userId":"15856587818203820318"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["## Create a Custom Dataset for SVHN database\n","import scipy.io as sio\n","from google.colab import drive\n","import matplotlib.pyplot as plt\n","import numpy as np\n","from PIL import Image\n","# Mount Google Drive\n","drive.mount('/content/drive')\n","data_path = '/content/drive/My Drive/Deep_Learning2020/Final_Project/Data22/'\n","results_path = '/content/drive/My Drive/Deep_Learning2020/Final_Project/Results/'\n","\n","# All the data will be loaded from the provided file in Data/mnist.t\n","import torch \n","import torch.nn as nn\n","import torchvision\n","import torchvision.transforms as tf\n","import matplotlib.pyplot as plt\n","from PIL import Image\n","import scipy.io as sio\n","from torchvision.datasets import ImageFolder\n","from torchvision.transforms import ToTensor\n","\n","\n","simpson = ImageFolder(root=data_path, transform=ToTensor())\n","train_loader = torch.utils.data.DataLoader(dataset=simpson,\n","                                           batch_size=64, \n","                                           shuffle=True)"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"rGHw5Qxndr5g","colab_type":"code","outputId":"a4115eb6-8972-45be-9e5d-c7189c13935a","executionInfo":{"status":"ok","timestamp":1591870251289,"user_tz":-120,"elapsed":13429,"user":{"displayName":"PAULA VILAMITJANA I","photoUrl":"","userId":"15856587818203820318"}},"colab":{"base_uri":"https://localhost:8080/","height":285}},"source":["images = next(iter(train_loader))\n","images_aux = images[0]\n","print(images_aux.shape)\n","image = images_aux[10,:,:,:]\n","plt.imshow(image.permute(1,2,0).squeeze().numpy())\n","plt.show()  "],"execution_count":0,"outputs":[{"output_type":"stream","text":["torch.Size([64, 3, 64, 64])\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"MLxl8rHaGdgC","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","\n","# Convolution + BatchNormnalization + ReLU block for the encoder\n","class ConvBNReLU(nn.Module):\n","  def __init__(self,in_channels, out_channels, pooling=False):\n","    super(ConvBNReLU, self).__init__()\n","    self.conv = nn.Conv2d(in_channels,out_channels,kernel_size=3,\n","                          padding = 1)\n","    self.bn = nn.BatchNorm2d(out_channels)\n","    self.relu = nn.ReLU(inplace=True)\n","\n","    self.pool = None\n","    if(pooling):\n","      self.pool = nn.AvgPool2d(2,2)\n","\n","  def forward(self,x):\n","    if(self.pool):\n","      out = self.pool(x)\n","    else:\n","      out = x\n","    out = self.relu(self.bn(self.conv(out)))   \n","    return out\n","\n","#  BatchNormnalization + ReLU block + Convolution for the decoder\n","class BNReLUConv(nn.Module):\n","  def __init__(self,in_channels, out_channels, pooling=False):\n","    super(BNReLUConv, self).__init__()\n","    self.bn = nn.BatchNorm2d(in_channels)\n","    self.relu = nn.ReLU(inplace=True)\n","    self.conv = nn.Conv2d(in_channels,out_channels,kernel_size=3,\n","                          padding = 1)\n","\n","    self.pool = None\n","    if(pooling):\n","      self.pool = nn.UpsamplingNearest2d(scale_factor=2)\n","\n","  def forward(self,x):\n","    out = self.relu(self.bn(x))\n","    if(self.pool):\n","      out = self.pool(out)\n","    out = self.conv(out)\n","    return out\n","\n","# Encoder definition with 3 COnv-BN-ReLU blocks and fully-connected layer\n","class Encoder(nn.Module):\n","  def __init__(self,out_features,base_channels=16):\n","    super(Encoder, self).__init__()\n","    self.layer1 = ConvBNReLU(3,base_channels,pooling=False)\n","    self.layer2 = ConvBNReLU(base_channels,base_channels*2,pooling=True)\n","    self.layer3 = ConvBNReLU(base_channels*2,base_channels*4,pooling=False)\n","    self.layer4 = ConvBNReLU(base_channels*4,base_channels*8,pooling=True)\n","    self.layer5 = ConvBNReLU(base_channels*8,base_channels*16,pooling=False)\n","    self.fc = nn.Linear(16*16*base_channels*16,out_features)\n","  \n","  def forward(self,x):\n","    out = self.layer1(x)\n","    out = self.layer2(out)\n","    out = self.layer3(out)\n","    out = self.layer4(out)\n","    out = self.layer5(out)\n","    return self.fc(out.view(x.shape[0],-1))\n","    \n","# Decoder definition with a fully-connected layer and 3 BN-ReLU-COnv blocks and \n","class Decoder(nn.Module):\n","  def __init__(self,out_features,base_channels=16):\n","    super(Decoder, self).__init__()\n","    self.base_channels = base_channels\n","    self.fc = nn.Linear(out_features,16*16*base_channels*16)\n","    self.layer5 = BNReLUConv(base_channels*16,base_channels*8,pooling=False)\n","    self.layer4 = BNReLUConv(base_channels*8,base_channels*4,pooling=True)\n","    self.layer3 = BNReLUConv(base_channels*4,base_channels*2,pooling=False)\n","    self.layer2 = BNReLUConv(base_channels*2,base_channels,pooling=True)\n","    self.layer1 = BNReLUConv(base_channels,3,pooling=False)\n","  \n","  def forward(self,x):\n","    out = self.fc(x)\n","    out = out.view(x.shape[0],self.base_channels*16,16,16)\n","    out = self.layer5(out)\n","    out = self.layer4(out)\n","    out = self.layer3(out)\n","    out = self.layer2(out)\n","    out = self.layer1(out)\n","    return torch.sigmoid(out)"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vUrqAof5JRjH","colab_type":"text"},"source":["## Sol. 2"]},{"cell_type":"code","metadata":{"id":"8mffaL-Jck17","colab_type":"code","colab":{}},"source":["# Discriminator similar to VAE encoder\n","class Discriminator(nn.Module):\n","  def __init__(self, base_channels=16):\n","    super(Discriminator, self).__init__()\n","    # last fully connected layer acts as a a binary classifier\n","    self.classifier = Encoder(1,base_channels)\n","\n","  # Forward pass obtaining the discriminator probability\n","  def forward(self,x):\n","    out = self.classifier(x)\n","    # use sigmoid to get the real/fake image probability\n","    return torch.sigmoid(out)\n","\n","# Generator is defined as VAE decoder\n","class Generator(nn.Module):\n","  def __init__(self,in_features,base_channels=16):\n","    super(Generator, self).__init__()\n","    self.base_channels = base_channels\n","    self.in_features = in_features\n","    self.decoder = Decoder(in_features,base_channels)\n","\n","  # Generate an image from vector z\n","  def forward(self,z):\n","    return torch.sigmoid(self.decoder(z))\n","\n","  # Sample a set of images from random vectors z\n","  def sample(self,n_samples=64,device='cpu'):\n","    samples_unit_normal = torch.randn((n_samples,self.in_features)).to(device)\n","    return self.decoder(samples_unit_normal)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"QxO9zVXucsQ0","colab_type":"code","colab":{}},"source":["# GAN Train function. We have a generator and discriminator models and their respective optimizers.\n","def train_GAN(gen, disc,  train_loader, optimizer_gen, optim_disc,\n","              num_epochs=10, model_name='gan_mnist.ckpt', device='cpu'):\n","    gen = gen.to(device)\n","    gen.train() # Set the generator in train mode\n","    disc = disc.to(device)\n","    disc.train() # Set the discriminator in train mode\n","\n","    total_step = len(train_loader)\n","    losses_list_disc = []\n","    losses_list_gen = []\n","\n","    # Iterate over epochs\n","    for epoch in range(num_epochs):\n","        # Iterate the dataset\n","        disc_loss_avg = 0\n","        gen_loss_avg = 0\n","        nBatches = 0\n","        update_generator = True\n","\n","        for i, (real_imagess) in enumerate(train_loader):\n","            # Get batch of samples and labels\n","            real_images = real_imagess[0]\n","            real_images = real_images.to(device)\n","            n_images = real_images.shape[0]\n","\n","            # Forward pass\n","            # Generate random images with the generator\n","            fake_images = gen.sample(n_images,device=device)\n","            \n","            # Use the discriminator to obtain the probabilties for real and generate imee\n","            prob_real = disc(real_images)\n","            prob_fake = disc(fake_images)\n","            \n","            # Generator loss\n","            gen_loss = -torch.log(prob_fake).mean()\n","            # Discriminator loss\n","            disc_loss = -0.5*(torch.log(prob_real) + torch.log(1-prob_fake)).mean()\n","\n","            \n","            # We are going to update the discriminator and generator parameters alternatively at each iteration\n","\n","            if(update_generator):\n","              # Optimize generator\n","              # Backward and optimize\n","              optimizer_gen.zero_grad()\n","              gen_loss.backward() # Necessary to not erase intermediate variables needed for computing disc_loss gradient\n","              optimizer_gen.step()\n","              update_generator = False\n","            else:           \n","              # Optimize discriminator\n","              # Backward and optimize\n","              optimizer_disc.zero_grad()\n","              disc_loss.backward()\n","              optimizer_disc.step()\n","              update_generator = True\n","                \n","\n","            disc_loss_avg += disc_loss.cpu().item()\n","            gen_loss_avg += gen_loss.cpu().item()\n","\n","            nBatches+=1\n","            if (i+1) % 40 == 0:\n","                print ('Epoch [{}/{}], Step [{}/{}], Gen. Loss: {:.4f}, Disc Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, gen_loss_avg / nBatches, disc_loss_avg / nBatches))\n","        print ('Epoch [{}/{}], Step [{}/{}], Gen. Loss: {:.4f}, Disc Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, gen_loss_avg / nBatches, disc_loss_avg / nBatches))\n","        # Save model\n","        losses_list_disc.append(disc_loss_avg / nBatches)\n","        losses_list_gen.append(gen_loss_avg / nBatches)\n","        torch.save(gan_gen.state_dict(), results_path+ '/' + model_name)\n","\n","        if ((epoch+1) % 20 == 0 or (epoch+1) == 1):\n","\n","          n_samples = 64\n","          n_iterpolations =50\n","\n","          x_gen = gan_gen.sample(n_samples,device=device)\n","          image_grid = make_grid(x_gen.cpu(),nrow=8,padding=1)\n","          plt.figure(figsize=(8,8))\n","          plt.title('Generated Images')\n","          plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n","          plt.show()\n","          \n","    return losses_list_disc, losses_list_gen"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"02jjjHfZcu_L","colab_type":"code","outputId":"09694fbf-1393-4000-fd2e-2b728afdf550","executionInfo":{"status":"error","timestamp":1591867816549,"user_tz":-120,"elapsed":62777,"user":{"displayName":"AINA VENDRELL I","photoUrl":"","userId":"04102729729446539106"}},"colab":{"base_uri":"https://localhost:8080/","height":341}},"source":["from torchvision.utils import make_grid\n","import matplotlib.pyplot as plt\n","import imageio\n","import numpy as np\n","\n","# Define Geneartor and Discriminator networks\n","gan_gen = Generator(64)\n","gan_disc = Discriminator()\n","\n","#Initialize indepdent optimizer for both networks\n","learning_rate_gen = .001\n","learning_rate_disc = .0001\n","optimizer_gen = torch.optim.Adam(gan_gen.parameters(),lr = learning_rate_gen, weight_decay=1e-5)\n","optimizer_disc = torch.optim.Adam(gan_disc.parameters(),lr = learning_rate_disc, weight_decay=1e-5)\n","\n","# Train the GAN\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","losses_list_disc, losses_list_gen = train_GAN(gan_gen,gan_disc, train_loader, optimizer_gen, optimizer_disc,\n","                      num_epochs=1000, model_name='gan_faces.ckpt', device=device)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-7-4a945e96f352>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cuda:0'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m losses_list_disc, losses_list_gen = train_GAN(gan_gen,gan_disc, train_loader, optimizer_gen, optimizer_disc,\n\u001b[0;32m---> 19\u001b[0;31m                       num_epochs=3000, model_name='gan_faces.ckpt', device=device)\n\u001b[0m","\u001b[0;32m<ipython-input-6-bf8ce8a734d5>\u001b[0m in \u001b[0;36mtrain_GAN\u001b[0;34m(gen, disc, train_loader, optimizer_gen, optim_disc, num_epochs, model_name, device)\u001b[0m\n\u001b[1;32m      2\u001b[0m def train_GAN(gen, disc,  train_loader, optimizer_gen, optim_disc,\n\u001b[1;32m      3\u001b[0m               num_epochs=10, model_name='gan_mnist.ckpt', device='cpu'):\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mgen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mgen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Set the generator in train mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mdisc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdisc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mto\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    441\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 443\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    444\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    445\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_backward_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    201\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmodule\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchildren\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m             \u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtensor_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    223\u001b[0m                 \u001b[0;31m# `with torch.no_grad():`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mno_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m                     \u001b[0mparam_applied\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m                 \u001b[0mshould_use_set_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompute_should_use_set_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_applied\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mshould_use_set_data\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mconvert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mconvert_to_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconvert_to_format\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_floating_point\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_blocking\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    442\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"Imu0XgqcTeJZ","colab_type":"code","colab":{}},"source":["# Loss function iterations\n","import matplotlib.pyplot as plt\n","plt.plot(losses_list_disc, label='Discriminator')\n","plt.plot(losses_list_gen, label='Generator')\n","plt.legend(loc = 'upper right')\n","plt.xlabel('Iterations')\n","plt.ylabel('Loss')\n","plt.title('LOSS ')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"TS0ce7agXIHW","colab_type":"code","colab":{}},"source":["import imageio\n","import numpy as np\n","from IPython.display import Image\n","\n","### Generate random samples\n","gan_gen = Generator(64)\n","gan_gen.load_state_dict(torch.load(results_path+'simpson_3000.ckpt'))\n","gan_gen = gan_gen.to(device)\n","gan_gen.eval()\n","\n","\n","n_samples = 64\n","n_iterpolations =50\n","z_init = torch.randn((n_samples,64)).to(device)\n","z_final = torch.randn((n_samples,64)).to(device)\n","\n","interpolation_images = []\n","for interp in range(0,n_iterpolations):\n","  interp_0_1 = float(interp) / (n_iterpolations-1)\n","  z = z_init*interp_0_1 + z_final*(1-interp_0_1)\n","  x_rec = gan_gen.decoder(z.to(device))\n","  image_grid = make_grid(x_rec.cpu(),nrow=8,padding=1)\n","  image_grid = image_grid.permute(1,2,0).detach().numpy()\n","\n","  interpolation_images.append((image_grid*255.0).astype(np.uint8))\n","interpolation_images += interpolation_images[::-1]\n","\n","imname = results_path+'simpson_interpolation_33000.gif'\n","imageio.mimsave(imname, interpolation_images, fps=25)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Gb_QtgvvuA_C","colab_type":"code","outputId":"5970b41a-73fe-4b46-fe04-50f15febfa7d","executionInfo":{"status":"error","timestamp":1591870406483,"user_tz":-120,"elapsed":2246,"user":{"displayName":"PAULA VILAMITJANA I","photoUrl":"","userId":"15856587818203820318"}},"colab":{"base_uri":"https://localhost:8080/","height":388}},"source":["# Load generator\n","gan_gen = Generator(64)\n","gan_gen.load_state_dict(torch.load(results_path+'vae_faces.ckpt'))\n","gan_gen.eval() # Put in eval model\n","gan_gen = gan_gen.to(device)\n","\n","# Generate random images from sampled vectors z and visualize them \n","x_gen = gan_gen.sample(64,device=device)\n","image_grid = make_grid(x_gen.cpu(),nrow=5,padding=1)\n","plt.figure(figsize=(40,40))\n","plt.imshow(image_grid.permute(1,2,0).detach().numpy())"],"execution_count":0,"outputs":[{"output_type":"error","ename":"RuntimeError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-19-c700c1265846>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Load generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgan_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGenerator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mgan_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresults_path\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;34m'vae_faces.ckpt'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgan_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meval\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Put in eval model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mgan_gen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgan_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36mload_state_dict\u001b[0;34m(self, state_dict, strict)\u001b[0m\n\u001b[1;32m    845\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merror_msgs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    846\u001b[0m             raise RuntimeError('Error(s) in loading state_dict for {}:\\n\\t{}'.format(\n\u001b[0;32m--> 847\u001b[0;31m                                self.__class__.__name__, \"\\n\\t\".join(error_msgs)))\n\u001b[0m\u001b[1;32m    848\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_IncompatibleKeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmissing_keys\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0munexpected_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Generator:\n\tUnexpected key(s) in state_dict: \"encoder.layer1.conv.weight\", \"encoder.layer1.conv.bias\", \"encoder.layer1.bn.weight\", \"encoder.layer1.bn.bias\", \"encoder.layer1.bn.running_mean\", \"encoder.layer1.bn.running_var\", \"encoder.layer1.bn.num_batches_tracked\", \"encoder.layer2.conv.weight\", \"encoder.layer2.conv.bias\", \"encoder.layer2.bn.weight\", \"encoder.layer2.bn.bias\", \"encoder.layer2.bn.running_mean\", \"encoder.layer2.bn.running_var\", \"encoder.layer2.bn.num_batches_tracked\", \"encoder.layer3.conv.weight\", \"encoder.layer3.conv.bias\", \"encoder.layer3.bn.weight\", \"encoder.layer3.bn.bias\", \"encoder.layer3.bn.running_mean\", \"encoder.layer3.bn.running_var\", \"encoder.layer3.bn.num_batches_tracked\", \"encoder.layer4.conv.weight\", \"encoder.layer4.conv.bias\", \"encoder.layer4.bn.weight\", \"encoder.layer4.bn.bias\", \"encoder.layer4.bn.running_mean\", \"encoder.layer4.bn.running_var\", \"encoder.layer4.bn.num_batches_tracked\", \"encoder.layer5.conv.weight\", \"encoder.layer5.conv.bias\", \"encoder.layer5.bn.weight\", \"encoder.layer5.bn.bias\", \"encoder.layer5.bn.running_mean\", \"encoder.layer5.bn.running_var\", \"encoder.layer5.bn.num_batches_tracked\", \"encoder.fc.weight\", \"encoder.fc.bias\". "]}]},{"cell_type":"code","metadata":{"id":"wotRPRxf2tsE","colab_type":"code","colab":{}},"source":["class VAE(nn.Module):\n","  def __init__(self, out_features,base_channels=16):\n","    super(VAE, self).__init__()\n","    # Initialize the encoder and decoder using a dimensionality out_features for the vector z\n","    self.out_features = out_features\n","    self.encoder = Encoder(out_features*2,base_channels)\n","    self.decoder = Decoder(out_features,base_channels)\n","\n","  # function to obtain the mu and sigma of z for a samples x\n","  def encode(self,x):\n","    aux = self.encoder(x)\n","    # get z mean\n","    z_mean = aux[:,0:self.out_features]\n","    # get z variance\n","    z_log_var = aux[:,self.out_features::]\n","    return z_mean, z_log_var\n","\n","  # function to generate a random sample z given mu and sigma\n","  def sample_z(self,z_mean,z_log_var):\n","    z_std = z_log_var.mul(0.5).exp()\n","    samples_unit_normal = torch.randn_like(z_mean)\n","    samples_z = samples_unit_normal*z_std + z_mean\n","    return samples_z\n","\n","  # (1) encode a sample \n","  # (2) obtain a random vector z from mu and sigma\n","  # (3) Reconstruct the image using the decoder\n","  def forward(self,x):\n","    z_mean, z_log_var = self.encode(x)\n","    samples_z = self.sample_z(z_mean,z_log_var)\n","    x_rec = self.decoder(samples_z)\n","    return x_rec, z_mean, z_log_var\n","\n","# Print summary of the mode\n","#print('FACES VAE Definition')\n","#vae = VAE(32)\n","#print(vae)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"JjpmpQ7s21rT","colab_type":"code","colab":{}},"source":["## Kullback-Leibler regularization computation\n","def kl_divergence(z_mean,z_log_var):\n","  kl_loss = 0.5 * torch.sum(  (torch.exp(z_log_var) + z_mean**2 - 1.0 - z_log_var),axis=1)\n","  return kl_loss.mean()\n","\n","# Train function\n","def train_VAE(vae,  train_loader, optimizer, kl_weight=0.001, num_epochs=10, model_name='vae_faces.ckpt', device='cpu'):\n","    vae.to(device)\n","    vae.train() # Set the model in train mode\n","    total_step = len(train_loader)\n","    losses_list = []\n","    KL_divergecnes = []\n","    criterion = nn.MSELoss() # Use mean-squared error to compare the original and reconstructe images\n","    \n","    # Iterate over epochs\n","    for epoch in range(num_epochs):\n","        # Iterate the dataset\n","        rec_loss_avg = 0\n","        kl_loss_avg = 0\n","        nBatches = 0\n","        for i, (imagess) in enumerate(train_loader):\n","            images = imagess[0]\n","            # Get batch of samples and labels\n","            images = images.to(device)\n","\n","            # Forward pass (get encoder variables and reconstructed images)\n","            x_rec, z_mean, z_log_var = vae(images)\n","\n","            reconstruction_loss = criterion(x_rec, images) # Reconstruction loss (x,x_rec)\n","            kl_loss = kl_divergence(z_mean, z_log_var) # Compute KL divergecnes KL( N(mu_x,sigma_x) || N(0,I))\n","            \n","            # Backward and optimize reconstruction loss and kl regularization\n","            optimizer.zero_grad()\n","            loss = reconstruction_loss + kl_loss*kl_weight # we use a weight to balance the importance of the KL loss\n","            loss.backward()\n","            optimizer.step()\n","\n","            rec_loss_avg += reconstruction_loss.cpu().item()\n","            kl_loss_avg += kl_loss.cpu().item()\n","\n","            nBatches+=1\n","            if (i+1) % 100 == 0:\n","                print ('Epoch [{}/{}], Step [{}/{}], Rec. Loss: {:.4f}, KL Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, rec_loss_avg / nBatches, kl_loss_avg / nBatches))\n","        print ('Epoch [{}/{}], Step [{}/{}], Rec. Loss: {:.4f}, KL Loss: {:.4f}' \n","                       .format(epoch+1, num_epochs, i+1, total_step, rec_loss_avg / nBatches, kl_loss_avg / nBatches))\n","        \n","        reconstruction_error = rec_loss_avg / nBatches\n","        losses_list.append(reconstruction_error)\n","        KL_divergecnes.append(kl_loss_avg / nBatches)\n","        # save trained model\n","        torch.save(vae.state_dict(), results_path+ '/' + model_name)\n","        \n","        if ((epoch+1) % 2 == 0 or (epoch+1) == 1):\n","          print ('Reconstruction Error: {}' .format(reconstruction_error))\n","\n","          plt.figure(figsize=(27,9))\n","          plt.subplot(1,3,1)\n","          plt.title('Original Images')\n","          image_grid = make_grid(images.cpu(),nrow=10,padding=1)\n","          plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n","\n","          plt.subplot(1,3,2)\n","          plt.title('Reconstructed Images')\n","          image_grid = make_grid(x_rec.cpu(),nrow=10,padding=1)\n","          plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n","\n","          n_samples = 64\n","          # Random vectors z~N(0,I)\n","          z = torch.randn((n_samples,vae.out_features)).to(device)\n","          x_rec = vae.decoder(z)\n","          plt.subplot(1,3,3)\n","          plt.title('Generated Images')\n","          image_grid = make_grid(x_rec.cpu(),nrow=8,padding=1)\n","          plt.imshow(image_grid.permute(1,2,0).detach().numpy())\n","          plt.show()\n","          \n","    return losses_list, KL_divergecnes"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"kMvMr4Ve24_c","colab_type":"code","outputId":"8e9206ae-9e5d-4815-df9f-7f54ccb05e6c","executionInfo":{"status":"error","timestamp":1591870573547,"user_tz":-120,"elapsed":134121,"user":{"displayName":"PAULA VILAMITJANA I","photoUrl":"","userId":"15856587818203820318"}},"colab":{"base_uri":"https://localhost:8080/"}},"source":["from torchvision.utils import make_grid\n","import matplotlib.pyplot as plt\n","import imageio\n","import numpy as np\n","\n","# Training a VAE on MNIST: z has 32 dimensions\n","# We use Adam optimizer which is tipically used in VAEs and GANs\n","\n","vae = VAE(64)\n","kl_weight=0.001 \n","\n","#Initialize optimizer \n","learning_rate = .001\n","optimizer = torch.optim.Adam(vae.parameters(),lr = learning_rate, weight_decay=1e-5)\n","device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n","\n","loss_list, KL_divergecnes = train_VAE(vae, train_loader, optimizer, kl_weight=kl_weight,\n","                      num_epochs=500, model_name='vae_faces500.ckpt', device=device)"],"execution_count":0,"outputs":[{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-23-2297a3319cc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m loss_list, KL_divergecnes = train_VAE(vae, train_loader, optimizer, kl_weight=kl_weight,\n\u001b[0;32m---> 18\u001b[0;31m                       num_epochs=500, model_name='vae_faces500.ckpt', device=device)\n\u001b[0m","\u001b[0;32m<ipython-input-22-189f0564df3d>\u001b[0m in \u001b[0;36mtrain_VAE\u001b[0;34m(vae, train_loader, optimizer, kl_weight, num_epochs, model_name, device)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0mkl_loss_avg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0mnBatches\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mimagess\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m             \u001b[0mimages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimagess\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m             \u001b[0;31m# Get batch of samples and labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    343\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__next__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    383\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    384\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 385\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    386\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    387\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mauto_collation\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    133\u001b[0m         \"\"\"\n\u001b[1;32m    134\u001b[0m         \u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m         \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m             \u001b[0msample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mdefault_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    169\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0maccimage_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 171\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mpil_loader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    173\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36mpil_loader\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m    151\u001b[0m     \u001b[0;31m# open path as file to avoid ResourceWarning (https://github.com/python-pillow/Pillow/issues/835)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m         \u001b[0mimg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    154\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mimg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'RGB'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode)\u001b[0m\n\u001b[1;32m   2816\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2817\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2818\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2820\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]}]}